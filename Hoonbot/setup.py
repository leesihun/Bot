#!/usr/bin/env python3
"""
Hoonbot Setup Script

Automatically obtains LLM_API_KEY from LLM_API_fast and sets up environment variables.
"""
import sys
import json
import subprocess
import os

# Fix Windows encoding issues
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

import httpx


def get_llm_api_token(llm_url: str, username: str = "admin", password: str = "administrator") -> str | None:
    """Get access token from LLM_API_fast."""
    print(f"\n[Setup] Connecting to LLM_API_fast at {llm_url}")

    try:
        response = httpx.post(
            f"{llm_url}/api/auth/login",
            json={"username": username, "password": password},
            timeout=10.0
        )
        response.raise_for_status()
        result = response.json()
        token = result.get("access_token")
        if token:
            print(f"[OK] Successfully obtained access token")
            return token
        else:
            print(f"[ERROR] Login response missing 'access_token'")
            return None
    except httpx.ConnectError:
        print(f"[ERROR] Cannot connect to LLM_API_fast")
        print(f"        Make sure it's running on {llm_url}")
        return None
    except httpx.HTTPStatusError as e:
        print(f"[ERROR] Login failed: {e.response.status_code}")
        if e.response.status_code == 401:
            print(f"        Invalid credentials (default: admin/administrator)")
        else:
            print(f"        {e.response.text}")
        return None
    except Exception as e:
        print(f"[ERROR] {e}")
        return None


def get_available_models(llm_url: str, token: str) -> list | None:
    """Get list of available models."""
    try:
        response = httpx.get(
            f"{llm_url}/v1/models",
            headers={"Authorization": f"Bearer {token}"},
            timeout=10.0
        )
        response.raise_for_status()
        result = response.json()
        models = result.get("data", [])
        if models:
            return [m.get("id") for m in models]
        return None
    except Exception as e:
        print(f"[Warning] Could not fetch model list: {e}")
        return None


def set_env_var(name: str, value: str) -> bool:
    """Set environment variable for current session and suggest persistence."""
    try:
        os.environ[name] = value
        print(f"[OK] Set {name}")
        return True
    except Exception as e:
        print(f"[ERROR] Failed to set {name}: {e}")
        return False


def save_env_file(llm_key: str, llm_model: str) -> bool:
    """Save environment variables to .env file."""
    env_content = f"""# Hoonbot Environment Variables
# Generated by setup.py on 2026-02-26

LLM_API_KEY={llm_key}
LLM_MODEL={llm_model}

# Optional: Customize these if needed
# HOONBOT_PORT=3939
# MESSENGER_PORT=3000
# LLM_API_URL=http://localhost:10007
"""

    try:
        with open(".env", "w") as f:
            f.write(env_content)
        print(f"[OK] Saved environment variables to .env")
        return True
    except Exception as e:
        print(f"[ERROR] Failed to save .env: {e}")
        return False


def main():
    print("\n" + "="*60)
    print("  Hoonbot Setup")
    print("="*60)

    # LLM_API_fast URL
    llm_url = os.environ.get("LLM_API_URL", "http://localhost:10007").rstrip("/")
    print(f"\nLLM_API_fast URL: {llm_url}")

    # Get token
    print("\nAttempting to login to LLM_API_fast...")
    token = get_llm_api_token(llm_url)

    if not token:
        print("\n[Setup] Could not obtain LLM_API_KEY automatically.")
        print("        You'll need to set it manually:")
        print("        export LLM_API_KEY='your_token_here'")
        return 1

    # Get available models
    print("\nFetching available models...")
    models = get_available_models(llm_url, token)

    llm_model = None
    if models:
        print(f"\nAvailable models:")
        for i, model in enumerate(models, 1):
            print(f"  {i}. {model}")

        # Pick first model by default
        llm_model = models[0]
        print(f"\nSelected: {llm_model}")
    else:
        print("\n[Warning] Could not fetch model list")
        print("          Enter model name manually after setup")
        llm_model = "default"

    # Set environment variables
    print("\nSetting environment variables...")
    set_env_var("LLM_API_KEY", token)
    set_env_var("LLM_MODEL", llm_model)

    # Save to .env file
    print("\nSaving to .env file...")
    save_env_file(token, llm_model)

    print("\n" + "="*60)
    print("  Setup Complete!")
    print("="*60)
    print("\nYou can now start Hoonbot:")
    print("  python hoonbot.py")
    print("\nTo manually set variables in the future:")
    print("  source .env    # Load from .env file")
    print("  # or")
    print(f"  export LLM_API_KEY='{token[:20]}...'")
    print(f"  export LLM_MODEL='{llm_model}'")
    print()

    return 0


if __name__ == "__main__":
    sys.exit(main())
